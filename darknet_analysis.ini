./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg

layer     filters    size              input                output
    0 conv     32  3 x 3 / 1   608 x 608 x   3   ->   608 x 608 x  32
    1 max          2 x 2 / 2   608 x 608 x  32   ->   304 x 304 x  32
    2 conv     64  3 x 3 / 1   304 x 304 x  32   ->   304 x 304 x  64
    3 max          2 x 2 / 2   304 x 304 x  64   ->   152 x 152 x  64
    4 conv    128  3 x 3 / 1   152 x 152 x  64   ->   152 x 152 x 128
    5 conv     64  1 x 1 / 1   152 x 152 x 128   ->   152 x 152 x  64
    6 conv    128  3 x 3 / 1   152 x 152 x  64   ->   152 x 152 x 128
    7 max          2 x 2 / 2   152 x 152 x 128   ->    76 x  76 x 128
    8 conv    256  3 x 3 / 1    76 x  76 x 128   ->    76 x  76 x 256
    9 conv    128  1 x 1 / 1    76 x  76 x 256   ->    76 x  76 x 128
   10 conv    256  3 x 3 / 1    76 x  76 x 128   ->    76 x  76 x 256
   11 max          2 x 2 / 2    76 x  76 x 256   ->    38 x  38 x 256
   12 conv    512  3 x 3 / 1    38 x  38 x 256   ->    38 x  38 x 512
   13 conv    256  1 x 1 / 1    38 x  38 x 512   ->    38 x  38 x 256
   14 conv    512  3 x 3 / 1    38 x  38 x 256   ->    38 x  38 x 512
   15 conv    256  1 x 1 / 1    38 x  38 x 512   ->    38 x  38 x 256
   16 conv    512  3 x 3 / 1    38 x  38 x 256   ->    38 x  38 x 512
   17 max          2 x 2 / 2    38 x  38 x 512   ->    19 x  19 x 512
   18 conv   1024  3 x 3 / 1    19 x  19 x 512   ->    19 x  19 x1024
   19 conv    512  1 x 1 / 1    19 x  19 x1024   ->    19 x  19 x 512
   20 conv   1024  3 x 3 / 1    19 x  19 x 512   ->    19 x  19 x1024
   21 conv    512  1 x 1 / 1    19 x  19 x1024   ->    19 x  19 x 512
   22 conv   1024  3 x 3 / 1    19 x  19 x 512   ->    19 x  19 x1024
   23 conv   1024  3 x 3 / 1    19 x  19 x1024   ->    19 x  19 x1024
   24 conv   1024  3 x 3 / 1    19 x  19 x1024   ->    19 x  19 x1024
   25 route  16
   26 conv     64  1 x 1 / 1    38 x  38 x 512   ->    38 x  38 x  64
   27 reorg              / 2    38 x  38 x  64   ->    19 x  19 x 256
   28 route  27 24
   29 conv   1024  3 x 3 / 1    19 x  19 x1280   ->    19 x  19 x1024
   30 conv    425  1 x 1 / 1    19 x  19 x1024   ->    19 x  19 x 425
   31 detection
mask_scale: Using default '1.000000'
Loading weights from yolo.weights...Done!
load_image_color: w 768, h 576, c 3
letterbox_image: w 608, h 608, c 3
network_predict: forward_network
forward_convolutional_layer, l.n = 32, l.groups = 1, l.size = 3, l.c = 3, l.out_w = 608, l.out_h = 608, l.xnor = 0, l.batch = 1, l.w = 608, l.h = 608, l.stride = 1, l.pad = 1, l.batch_normalize = 1, l.n = 32, l.binary = 0, l.nweights = 864, l.activation = 7
cpu: 0 0 32 369664 27 1.000000 27 369664 1.000000 369664
forward_batchnorm_layer, l.type = 0, net.train = 0
forward_network cpu: i:0, in (h, w, c): (608, 608, 3), out (h, w, c): (608, 608, 32), l.truth: 0, l.batch: 1
forward_network cpu: i:1, in (h, w, c): (608, 608, 32), out (h, w, c): (304, 304, 32), l.truth: 0, l.batch: 1
forward_convolutional_layer, l.n = 64, l.groups = 1, l.size = 3, l.c = 32, l.out_w = 304, l.out_h = 304, l.xnor = 0, l.batch = 1, l.w = 304, l.h = 304, l.stride = 1, l.pad = 1, l.batch_normalize = 1, l.n = 64, l.binary = 0, l.nweights = 18432, l.activation = 7
cpu: 0 0 64 92416 288 1.000000 288 92416 1.000000 92416
forward_batchnorm_layer, l.type = 0, net.train = 0
forward_network cpu: i:2, in (h, w, c): (304, 304, 32), out (h, w, c): (304, 304, 64), l.truth: 0, l.batch: 1
forward_network cpu: i:3, in (h, w, c): (304, 304, 64), out (h, w, c): (152, 152, 64), l.truth: 0, l.batch: 1
forward_convolutional_layer, l.n = 128, l.groups = 1, l.size = 3, l.c = 64, l.out_w = 152, l.out_h = 152, l.xnor = 0, l.batch = 1, l.w = 152, l.h = 152, l.stride = 1, l.pad = 1, l.batch_normalize = 1, l.n = 128, l.binary = 0, l.nweights = 73728, l.activation = 7
cpu: 0 0 128 23104 576 1.000000 576 23104 1.000000 23104
forward_batchnorm_layer, l.type = 0, net.train = 0
forward_network cpu: i:4, in (h, w, c): (152, 152, 64), out (h, w, c): (152, 152, 128), l.truth: 0, l.batch: 1
forward_convolutional_layer, l.n = 64, l.groups = 1, l.size = 1, l.c = 128, l.out_w = 152, l.out_h = 152, l.xnor = 0, l.batch = 1, l.w = 152, l.h = 152, l.stride = 1, l.pad = 0, l.batch_normalize = 1, l.n = 64, l.binary = 0, l.nweights = 8192, l.activation = 7
cpu: 0 0 64 23104 128 1.000000 128 23104 1.000000 23104
forward_batchnorm_layer, l.type = 0, net.train = 0
forward_network cpu: i:5, in (h, w, c): (152, 152, 128), out (h, w, c): (152, 152, 64), l.truth: 0, l.batch: 1
forward_convolutional_layer, l.n = 128, l.groups = 1, l.size = 3, l.c = 64, l.out_w = 152, l.out_h = 152, l.xnor = 0, l.batch = 1, l.w = 152, l.h = 152, l.stride = 1, l.pad = 1, l.batch_normalize = 1, l.n = 128, l.binary = 0, l.nweights = 73728, l.activation = 7
cpu: 0 0 128 23104 576 1.000000 576 23104 1.000000 23104
forward_batchnorm_layer, l.type = 0, net.train = 0
forward_network cpu: i:6, in (h, w, c): (152, 152, 64), out (h, w, c): (152, 152, 128), l.truth: 0, l.batch: 1
forward_network cpu: i:7, in (h, w, c): (152, 152, 128), out (h, w, c): (76, 76, 128), l.truth: 0, l.batch: 1
forward_convolutional_layer, l.n = 256, l.groups = 1, l.size = 3, l.c = 128, l.out_w = 76, l.out_h = 76, l.xnor = 0, l.batch = 1, l.w = 76, l.h = 76, l.stride = 1, l.pad = 1, l.batch_normalize = 1, l.n = 256, l.binary = 0, l.nweights = 294912, l.activation = 7
cpu: 0 0 256 5776 1152 1.000000 1152 5776 1.000000 5776
forward_batchnorm_layer, l.type = 0, net.train = 0
forward_network cpu: i:8, in (h, w, c): (76, 76, 128), out (h, w, c): (76, 76, 256), l.truth: 0, l.batch: 1
forward_convolutional_layer, l.n = 128, l.groups = 1, l.size = 1, l.c = 256, l.out_w = 76, l.out_h = 76, l.xnor = 0, l.batch = 1, l.w = 76, l.h = 76, l.stride = 1, l.pad = 0, l.batch_normalize = 1, l.n = 128, l.binary = 0, l.nweights = 32768, l.activation = 7
cpu: 0 0 128 5776 256 1.000000 256 5776 1.000000 5776
forward_batchnorm_layer, l.type = 0, net.train = 0
forward_network cpu: i:9, in (h, w, c): (76, 76, 256), out (h, w, c): (76, 76, 128), l.truth: 0, l.batch: 1
forward_convolutional_layer, l.n = 256, l.groups = 1, l.size = 3, l.c = 128, l.out_w = 76, l.out_h = 76, l.xnor = 0, l.batch = 1, l.w = 76, l.h = 76, l.stride = 1, l.pad = 1, l.batch_normalize = 1, l.n = 256, l.binary = 0, l.nweights = 294912, l.activation = 7
cpu: 0 0 256 5776 1152 1.000000 1152 5776 1.000000 5776
forward_batchnorm_layer, l.type = 0, net.train = 0
forward_network cpu: i:10, in (h, w, c): (76, 76, 128), out (h, w, c): (76, 76, 256), l.truth: 0, l.batch: 1
forward_network cpu: i:11, in (h, w, c): (76, 76, 256), out (h, w, c): (38, 38, 256), l.truth: 0, l.batch: 1
forward_convolutional_layer, l.n = 512, l.groups = 1, l.size = 3, l.c = 256, l.out_w = 38, l.out_h = 38, l.xnor = 0, l.batch = 1, l.w = 38, l.h = 38, l.stride = 1, l.pad = 1, l.batch_normalize = 1, l.n = 512, l.binary = 0, l.nweights = 1179648, l.activation = 7
cpu: 0 0 512 1444 2304 1.000000 2304 1444 1.000000 1444
forward_batchnorm_layer, l.type = 0, net.train = 0
forward_network cpu: i:12, in (h, w, c): (38, 38, 256), out (h, w, c): (38, 38, 512), l.truth: 0, l.batch: 1
forward_convolutional_layer, l.n = 256, l.groups = 1, l.size = 1, l.c = 512, l.out_w = 38, l.out_h = 38, l.xnor = 0, l.batch = 1, l.w = 38, l.h = 38, l.stride = 1, l.pad = 0, l.batch_normalize = 1, l.n = 256, l.binary = 0, l.nweights = 131072, l.activation = 7
cpu: 0 0 256 1444 512 1.000000 512 1444 1.000000 1444
forward_batchnorm_layer, l.type = 0, net.train = 0
forward_network cpu: i:13, in (h, w, c): (38, 38, 512), out (h, w, c): (38, 38, 256), l.truth: 0, l.batch: 1
forward_convolutional_layer, l.n = 512, l.groups = 1, l.size = 3, l.c = 256, l.out_w = 38, l.out_h = 38, l.xnor = 0, l.batch = 1, l.w = 38, l.h = 38, l.stride = 1, l.pad = 1, l.batch_normalize = 1, l.n = 512, l.binary = 0, l.nweights = 1179648, l.activation = 7
cpu: 0 0 512 1444 2304 1.000000 2304 1444 1.000000 1444
forward_batchnorm_layer, l.type = 0, net.train = 0
forward_network cpu: i:14, in (h, w, c): (38, 38, 256), out (h, w, c): (38, 38, 512), l.truth: 0, l.batch: 1
forward_convolutional_layer, l.n = 256, l.groups = 1, l.size = 1, l.c = 512, l.out_w = 38, l.out_h = 38, l.xnor = 0, l.batch = 1, l.w = 38, l.h = 38, l.stride = 1, l.pad = 0, l.batch_normalize = 1, l.n = 256, l.binary = 0, l.nweights = 131072, l.activation = 7
cpu: 0 0 256 1444 512 1.000000 512 1444 1.000000 1444
forward_batchnorm_layer, l.type = 0, net.train = 0
forward_network cpu: i:15, in (h, w, c): (38, 38, 512), out (h, w, c): (38, 38, 256), l.truth: 0, l.batch: 1
forward_convolutional_layer, l.n = 512, l.groups = 1, l.size = 3, l.c = 256, l.out_w = 38, l.out_h = 38, l.xnor = 0, l.batch = 1, l.w = 38, l.h = 38, l.stride = 1, l.pad = 1, l.batch_normalize = 1, l.n = 512, l.binary = 0, l.nweights = 1179648, l.activation = 7
cpu: 0 0 512 1444 2304 1.000000 2304 1444 1.000000 1444
forward_batchnorm_layer, l.type = 0, net.train = 0
forward_network cpu: i:16, in (h, w, c): (38, 38, 256), out (h, w, c): (38, 38, 512), l.truth: 0, l.batch: 1
forward_network cpu: i:17, in (h, w, c): (38, 38, 512), out (h, w, c): (19, 19, 512), l.truth: 0, l.batch: 1
forward_convolutional_layer, l.n = 1024, l.groups = 1, l.size = 3, l.c = 512, l.out_w = 19, l.out_h = 19, l.xnor = 0, l.batch = 1, l.w = 19, l.h = 19, l.stride = 1, l.pad = 1, l.batch_normalize = 1, l.n = 1024, l.binary = 0, l.nweights = 4718592, l.activation = 7
cpu: 0 0 1024 361 4608 1.000000 4608 361 1.000000 361
forward_batchnorm_layer, l.type = 0, net.train = 0
forward_network cpu: i:18, in (h, w, c): (19, 19, 512), out (h, w, c): (19, 19, 1024), l.truth: 0, l.batch: 1
forward_convolutional_layer, l.n = 512, l.groups = 1, l.size = 1, l.c = 1024, l.out_w = 19, l.out_h = 19, l.xnor = 0, l.batch = 1, l.w = 19, l.h = 19, l.stride = 1, l.pad = 0, l.batch_normalize = 1, l.n = 512, l.binary = 0, l.nweights = 524288, l.activation = 7
cpu: 0 0 512 361 1024 1.000000 1024 361 1.000000 361
forward_batchnorm_layer, l.type = 0, net.train = 0
forward_network cpu: i:19, in (h, w, c): (19, 19, 1024), out (h, w, c): (19, 19, 512), l.truth: 0, l.batch: 1
forward_convolutional_layer, l.n = 1024, l.groups = 1, l.size = 3, l.c = 512, l.out_w = 19, l.out_h = 19, l.xnor = 0, l.batch = 1, l.w = 19, l.h = 19, l.stride = 1, l.pad = 1, l.batch_normalize = 1, l.n = 1024, l.binary = 0, l.nweights = 4718592, l.activation = 7
cpu: 0 0 1024 361 4608 1.000000 4608 361 1.000000 361
forward_batchnorm_layer, l.type = 0, net.train = 0
forward_network cpu: i:20, in (h, w, c): (19, 19, 512), out (h, w, c): (19, 19, 1024), l.truth: 0, l.batch: 1
forward_convolutional_layer, l.n = 512, l.groups = 1, l.size = 1, l.c = 1024, l.out_w = 19, l.out_h = 19, l.xnor = 0, l.batch = 1, l.w = 19, l.h = 19, l.stride = 1, l.pad = 0, l.batch_normalize = 1, l.n = 512, l.binary = 0, l.nweights = 524288, l.activation = 7
cpu: 0 0 512 361 1024 1.000000 1024 361 1.000000 361
forward_batchnorm_layer, l.type = 0, net.train = 0
forward_network cpu: i:21, in (h, w, c): (19, 19, 1024), out (h, w, c): (19, 19, 512), l.truth: 0, l.batch: 1
forward_convolutional_layer, l.n = 1024, l.groups = 1, l.size = 3, l.c = 512, l.out_w = 19, l.out_h = 19, l.xnor = 0, l.batch = 1, l.w = 19, l.h = 19, l.stride = 1, l.pad = 1, l.batch_normalize = 1, l.n = 1024, l.binary = 0, l.nweights = 4718592, l.activation = 7
cpu: 0 0 1024 361 4608 1.000000 4608 361 1.000000 361
forward_batchnorm_layer, l.type = 0, net.train = 0
forward_network cpu: i:22, in (h, w, c): (19, 19, 512), out (h, w, c): (19, 19, 1024), l.truth: 0, l.batch: 1
forward_convolutional_layer, l.n = 1024, l.groups = 1, l.size = 3, l.c = 1024, l.out_w = 19, l.out_h = 19, l.xnor = 0, l.batch = 1, l.w = 19, l.h = 19, l.stride = 1, l.pad = 1, l.batch_normalize = 1, l.n = 1024, l.binary = 0, l.nweights = 9437184, l.activation = 7
cpu: 0 0 1024 361 9216 1.000000 9216 361 1.000000 361
forward_batchnorm_layer, l.type = 0, net.train = 0
forward_network cpu: i:23, in (h, w, c): (19, 19, 1024), out (h, w, c): (19, 19, 1024), l.truth: 0, l.batch: 1
forward_convolutional_layer, l.n = 1024, l.groups = 1, l.size = 3, l.c = 1024, l.out_w = 19, l.out_h = 19, l.xnor = 0, l.batch = 1, l.w = 19, l.h = 19, l.stride = 1, l.pad = 1, l.batch_normalize = 1, l.n = 1024, l.binary = 0, l.nweights = 9437184, l.activation = 7
cpu: 0 0 1024 361 9216 1.000000 9216 361 1.000000 361
forward_batchnorm_layer, l.type = 0, net.train = 0
forward_network cpu: i:24, in (h, w, c): (19, 19, 1024), out (h, w, c): (19, 19, 1024), l.truth: 0, l.batch: 1
forward_network cpu: i:25, in (h, w, c): (0, 0, 0), out (h, w, c): (38, 38, 512), l.truth: 0, l.batch: 1
forward_convolutional_layer, l.n = 64, l.groups = 1, l.size = 1, l.c = 512, l.out_w = 38, l.out_h = 38, l.xnor = 0, l.batch = 1, l.w = 38, l.h = 38, l.stride = 1, l.pad = 0, l.batch_normalize = 1, l.n = 64, l.binary = 0, l.nweights = 32768, l.activation = 7
cpu: 0 0 64 1444 512 1.000000 512 1444 1.000000 1444
forward_batchnorm_layer, l.type = 0, net.train = 0
forward_network cpu: i:26, in (h, w, c): (38, 38, 512), out (h, w, c): (38, 38, 64), l.truth: 0, l.batch: 1
forward_network cpu: i:27, in (h, w, c): (38, 38, 64), out (h, w, c): (19, 19, 256), l.truth: 0, l.batch: 1
forward_network cpu: i:28, in (h, w, c): (0, 0, 0), out (h, w, c): (19, 19, 1280), l.truth: 0, l.batch: 1
forward_convolutional_layer, l.n = 1024, l.groups = 1, l.size = 3, l.c = 1280, l.out_w = 19, l.out_h = 19, l.xnor = 0, l.batch = 1, l.w = 19, l.h = 19, l.stride = 1, l.pad = 1, l.batch_normalize = 1, l.n = 1024, l.binary = 0, l.nweights = 11796480, l.activation = 7
cpu: 0 0 1024 361 11520 1.000000 11520 361 1.000000 361
forward_batchnorm_layer, l.type = 0, net.train = 0
forward_network cpu: i:29, in (h, w, c): (19, 19, 1280), out (h, w, c): (19, 19, 1024), l.truth: 0, l.batch: 1
forward_convolutional_layer, l.n = 425, l.groups = 1, l.size = 1, l.c = 1024, l.out_w = 19, l.out_h = 19, l.xnor = 0, l.batch = 1, l.w = 19, l.h = 19, l.stride = 1, l.pad = 0, l.batch_normalize = 0, l.n = 425, l.binary = 0, l.nweights = 435200, l.activation = 3
cpu: 0 0 425 361 1024 1.000000 1024 361 1.000000 361
forward_network cpu: i:30, in (h, w, c): (19, 19, 1024), out (h, w, c): (19, 19, 425), l.truth: 0, l.batch: 1
forward_network cpu: i:31, in (h, w, c): (19, 19, 425), out (h, w, c): (19, 19, 425), l.truth: 0, l.batch: 1
data/dog.jpg: Predicted in 147.286407 seconds.
dog: 82%
car: 27%
truck: 65%
bicycle: 85%

im2col:
width_col = 608
height_col = 608
channels_col = input kernel by ch size (3 * 3 * 3 = 27)
loop by channels_col
  w_offset = 0, 1, 2, 0, 1, 2, 0, 1, ...
  h_offset = 0, 0, 0, 1, 1, 1, 2, 2, 2, 0, 0, 0, 1, 1, 1, 2, 2, 2, ...
  c_im     = 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2
  loop by height_col
    loop by width_col
      im_row = all 0 for h = 0, c = 0
               all 1 for h = 1, c = 0
               all 2 for h = 2, c = 0
               ...
               all 1 for h = 0, c = 3
               all 2 for h = 1, c = 3
               all 3 for h = 2, c = 3
               ...
               all 2 for h = 0, c = 6
               all 3 for h = 1, c = 6
               all 4 for h = 2, c = 6
               ...
      im_col = increase by 1 for c = 0
               increase by 1 + 1 for c = 1
               ...
   col_index = increase by 1 for h = 0, c = 0
               increase by 1 + next line for h = 1, c = 0
               increase by 1 + next 2line for h = 2, c = 0
               ...
               increase by 1 + next ch for h = 0, c = 1
               increase by 1 + next ch + next line for h = 1, c = 1
               increase by 1 + next ch + next 2line for h = 2, c = 1
               ...
               increase by 1 + next 2ch for h = 0, c = 2
               increase by 1 + next 2ch + next line for h = 1, c = 2
               increase by 1 + next 2ch + next 2line for h = 2, c = 2
      col_index = output index
      im_col - pad = input x index
      im_row - pad = input y index
      c_im         = input ch index
stack structure =
output[ch 0]
kernel[ 0]
(-1,   -1, 0) (0,   -1, 0) (1,   -1, 0) (2,   -1, 0) ... (606,   -1, 0)
(-1,    0, 0) (0,    0, 0) (1,    0, 0) (2,    0, 0) ... (606,    0, 0)
(-1,    1, 0) (0,    1, 0) (1,    1, 0) (2,    1, 0) ... (606,    1, 0)
(-1,    2, 0) (0,    2, 0) (1,    2, 0) (2,    2, 0) ... (606,    2, 0)
...
(-1,  606, 0) (0,  606, 0) (1,  606, 0) (2,  606, 0) ... (606,  606, 0)
kernel[ 1]
( 0,   -1, 0) (1,   -1, 0) (2,   -1, 0) (3,   -1, 0) ... (607,   -1, 0)
( 0,    0, 0) (1,    0, 0) (2,    0, 0) (3,    0, 0) ... (607,    0, 0)
( 0,    1, 0) (1,    1, 0) (2,    1, 0) (3,    1, 0) ... (607,    1, 0)
( 0,    2, 0) (1,    2, 0) (2,    2, 0) (3,    2, 0) ... (607,    2, 0)
...
( 0,  606, 0) (1,  606, 0) (2,  606, 0) (3,  606, 0) ... (607,  606, 0)
kernel[ 2]
( 1,   -1, 0) (2,   -1, 0) (3,   -1, 0) (4,   -1, 0) ... (608,   -1, 0)
( 1,    0, 0) (2,    0, 0) (3,    0, 0) (4,    0, 0) ... (608,    0, 0)
( 1,    1, 0) (2,    1, 0) (3,    1, 0) (4,    1, 0) ... (608,    1, 0)
( 1,    2, 0) (2,    2, 0) (3,    2, 0) (4,    2, 0) ... (608,    2, 0)
...
( 1,  606, 0) (2,  606, 0) (3,  606, 0) (4,  606, 0) ... (608,  606, 0)
kernel[ 3]
(-1,    0, 0) (0,    0, 0) (1,    0, 0) (2,    0, 0) ... (606,    0, 0)
(-1,    1, 0) (0,    1, 0) (1,    1, 0) (2,    1, 0) ... (606,    1, 0)
(-1,    2, 0) (0,    2, 0) (1,    2, 0) (2,    2, 0) ... (606,    2, 0)
(-1,    3, 0) (0,    3, 0) (1,    3, 0) (2,    3, 0) ... (606,    3, 0)
...
(-1,  607, 0) (0,  607, 0) (1,  607, 0) (2,  607, 0) ... (606,  607, 0)
...
output[ch 1]
kernel[ 0 + 27]
same input image

convolution:
output (c) = output image size (N, loop j) x output ch size (M, loop i)
c should be initialized
weight (a) = input kernel by ch size (K, loop k) x output ch size (M, loop i)
K = kernel width * kernel height * input ch size
input (b) = output image size (N, loop j) x input kernel by ch size (K, loop k)
so, each output = sum of (fixed weight (a) * input (b)) by loop j (N)
-> for one output ch, one output pixel, sum of K products needed
-> sum of K products needed - kxk pixels for each ch

batchnorm:
output (l.output) = l.batch x l.out_c x l.out_h * l.out_w
mean (l.rolling_mean) = l.out_c
variance (l.rolling_variance) = l.out_c
scale (l.scales) = l.out_c
biases (l.biases) = l.out_c

activate:
typedef enum{
    LOGISTIC, RELU, RELIE, LINEAR, RAMP, TANH, PLSE, LEAKY, ELU, LOGGY, STAIR, HARDTAN, LHTAN
} ACTIVATION;
float leaky_activate(float x){return (x>0) ? x : .1*x;}

gcc main.c -lm -O3

